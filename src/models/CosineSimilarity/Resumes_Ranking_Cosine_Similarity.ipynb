{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fa9594b-c02a-4182-a0ce-036eecc4fa95",
   "metadata": {},
   "source": [
    "# The first step is to import the required librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2cac044-102c-4726-b638-8bfc4247df28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"This module provides a portable way of using operating system dependent functionality. If you\n",
    "just want to read or write a file see open(), if you want to manipulate paths, see the os.path \n",
    "module, and if you want to read all the lines in all the files on the command line see the \n",
    "fileinput module\"\"\"\n",
    "import os\n",
    "\"\"\"\n",
    "pdfplumber is a powerful library that allows for easy extraction of text and data from PDFs, \n",
    "making it a valuable tool for data analysis and automation tasks.\n",
    "\"\"\"\n",
    "import pdfplumber\n",
    "\"\"\"The Natural Language Toolkit (NLTK) is an open source Python library for Natural Language Processing\"\"\"\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\"\"\"scikit-learn is a Python module for machine learning built on top of SciPy and is distributed\n",
    "under the 3-Clause BSD license.\"\"\"\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\"\"\"\n",
    "The csv library provides functionality to both read from and write to CSV files. Designed to work out\n",
    "of the box with Excel-generated CSV files, it is easily adapted to work with a variety of CSV formats.\n",
    "The csv library contains objects and other code to read, write, and process data from and to CSV files.\n",
    "\"\"\"\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a24335-92be-43dc-a049-c6fdc33ba664",
   "metadata": {},
   "source": [
    "# Extraction of text  from  job description and remove stop Wrods from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4466c21-38cd-482e-b169-a2ca9bc82b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the job description from a PDF\n",
    "with pdfplumber.open(r\"C:\\Users\\kabir\\Desktop\\Projects\\Resumes_Ranking_Scranning\\data\\raw\\Data\\JobDescription\\10399912.pdf\") as pdf:\n",
    "    job_description_text = \"\"\n",
    "    for page in pdf.pages:\n",
    "        job_description_text += page.extract_text()\n",
    "# Process the job description text\n",
    "stop_words = stopwords.words('english') \n",
    "# we will create a vectorizer object using `TfidfVectorizer()` and fit and transform the text data into vectors\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "job_description_tfidf = tfidf_vectorizer.fit_transform([job_description_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2592cf6-a474-4522-9155-65f1dc7bde63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n returns the term-document matrix that you want to obtain. So save what it returns, and use todense, \\n as it will be in sparse format:\\nReturns: X : sparse matrix, [n_samples, n_features]. Tf-idf-weighted document-term matrix.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " returns the term-document matrix that you want to obtain. So save what it returns, and use todense, \n",
    " as it will be in sparse format:\n",
    "Returns: X : sparse matrix, [n_samples, n_features]. Tf-idf-weighted document-term matrix.\n",
    "\"\"\"\n",
    "#job_description_tfidf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04853135-e795-4d0b-b5b6-720f790aa358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the job description from a PDF\n",
    "with pdfplumber.open(r\"C:\\Users\\kabir\\Desktop\\Projects\\Resumes_Ranking_Scranning\\data\\raw\\Data\\JobDescription\\10399912.pdf\") as pdf:\n",
    "    job_description_text = \"\"\n",
    "    for page in pdf.pages:\n",
    "        job_description_text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eff1cd5f-c7a0-44b4-8573-c747ee506073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Folder containing resume files\n",
    "resume_folder = r\"C:\\Users\\kabir\\Desktop\\Projects\\Resumes_Ranking\\data\\raw\\Data\\HR\"\n",
    "# Process each resume and calculate cosine similarity\n",
    "similarities = {}\n",
    "for resume_file in os.listdir(resume_folder):\n",
    "    if resume_file.endswith('.pdf'):\n",
    "        try:\n",
    "            with pdfplumber.open(os.path.join(resume_folder, resume_file)) as pdf:\n",
    "                resume_text = \"\"\n",
    "                for page in pdf.pages:\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        resume_text += page_text  # Append page text if not empty\n",
    "                \n",
    "                if resume_text.strip():  # Ensure extracted text is not empty\n",
    "                    # Process the resume text\n",
    "                    resume_tfidf = tfidf_vectorizer.transform([resume_text])\n",
    "                    \n",
    "                    # Calculate cosine similarity\n",
    "                    similarity = cosine_similarity(job_description_tfidf, resume_tfidf)\n",
    "                    similarities[resume_file] = similarity[0][0]\n",
    "                    #print(type(similarity))\n",
    "                    #print(similarities[resume_file])\n",
    "                \n",
    "                else:\n",
    "                    print(f\"Warning: Empty text in {resume_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {resume_file}: {e}\")\n",
    "\n",
    "# Sort and rank resumes based on cosine similarity\n",
    "\"\"\"\n",
    "Parameter\tDescription\n",
    "iterable\tRequired. The sequence to sort, list, dictionary, tuple etc.\n",
    "key\tOptional. A Function to execute to decide the order. Default is None\n",
    "reverse\tOptional. A Boolean. False will sort ascending, True will sort descending. Default is False\n",
    "\"\"\"\n",
    "#print(similarities)\n",
    "CVs = sorted(similarities.items(),key=lambda x: x[1],  reverse=True)\n",
    "#print(sorted_resumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b0ed4d3-ac95-4910-8e0f-c8adf125547c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to similarity_scores.csv\n"
     ]
    }
   ],
   "source": [
    "def save_as_csv_File(csv_file_name,fieldnames,sorted_resumes):\n",
    "\n",
    "    # Write the results to the CSV file\n",
    "    with open(output_csv_file, mode='w', newline='') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        #we will create header in our csv file\n",
    "        writer.writeheader()\n",
    "        #we fill  our csv file with \n",
    "        for idx, (resume_file, similarity) in enumerate(sorted_resumes, start=1):\n",
    "            writer.writerow({'Rank': idx, 'Resume File': resume_file, 'Cosine Similarity': similarity})\n",
    "\n",
    "    print(f\"Results saved to {output_csv_file}\")\n",
    "    \n",
    "CVs = sorted(similarities.items(),key=lambda x: x[1],  reverse=True)   \n",
    "Rank_ResumeFile_CosineSimilarity = ['Rank', 'Resume File', 'Cosine Similarity']\n",
    "output_csv_file = 'similarity_scores.csv'\n",
    "save_as_csv_File(output_csv_file,Rank_ResumeFile_CosineSimilarity,CVs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31242c48-3c0d-4d8d-a5ff-942a1a96eb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
