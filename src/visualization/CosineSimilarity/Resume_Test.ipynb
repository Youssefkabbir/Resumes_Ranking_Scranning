{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a438a48a-b253-47d3-aee3-b6bad71988a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Cell was executed without error\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import csv\n",
    "print('the Cell was executed without error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28796911-ffe1-4019-92db-ac86d8825cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the job description from a PDF\n",
    "with pdfplumber.open(r\"C:\\Users\\kabir\\Desktop\\Projects\\Resumes_Ranking\\data\\raw\\Data\\JobDescription\\10399912.pdf\") as pdf:\n",
    "    job_description_text = \"\"\n",
    "    for page in pdf.pages:\n",
    "        job_description_text += page.extract_text()\n",
    "# Process the job description text\n",
    "stop_words = stopwords.words('english') \n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "job_description_tfidf = tfidf_vectorizer.fit_transform([job_description_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1aa355a-4a94-4143-83e5-889a3c50d836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(job_description_tfidf.shape)\n",
    "#job_description_tfidf\n",
    "#job_description_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "573bdca1-b0a8-4006-8c04-92f3fb8a26dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999989\n",
      "0.44110592258526726\n",
      "0.43056401330681876\n",
      "0.5860755334317378\n",
      "0.5408665275774263\n",
      "Results saved to similarity_scores.csv\n"
     ]
    }
   ],
   "source": [
    "# Folder containing resume files\n",
    "resume_folder = r\"C:\\Users\\kabir\\Desktop\\Projects\\Resumes_Ranking\\data\\raw\\Data\\HR\"\n",
    "# Process each resume and calculate cosine similarity\n",
    "similarities = {}\n",
    "for resume_file in os.listdir(resume_folder):\n",
    "    if resume_file.endswith('.pdf'):\n",
    "        try:\n",
    "            with pdfplumber.open(os.path.join(resume_folder, resume_file)) as pdf:\n",
    "                resume_text = \"\"\n",
    "                for page in pdf.pages:\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        resume_text += page_text  # Append page text if not empty\n",
    "                \n",
    "                if resume_text.strip():  # Ensure extracted text is not empty\n",
    "                    # Process the resume text\n",
    "                    resume_tfidf = tfidf_vectorizer.transform([resume_text])\n",
    "                    \n",
    "                    # Calculate cosine similarity\n",
    "                    similarity = cosine_similarity(job_description_tfidf, resume_tfidf)\n",
    "                    similarities[resume_file] = similarity[0][0]\n",
    "                    print(similarities[resume_file])\n",
    "                \n",
    "                else:\n",
    "                    print(f\"Warning: Empty text in {resume_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {resume_file}: {e}\")\n",
    "\n",
    "# Sort and rank resumes based on cosine similarity\n",
    "sorted_resumes = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Specify the CSV output file path in Kaggle's working directory\n",
    "output_csv_file = 'similarity_scores.csv'\n",
    "\n",
    "# Write the results to the CSV file\n",
    "with open(output_csv_file, mode='w', newline='') as csv_file:\n",
    "    fieldnames = ['Rank', 'Resume File', 'Cosine Similarity']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for idx, (resume_file, similarity) in enumerate(sorted_resumes, start=1):\n",
    "        writer.writerow({'Rank': idx, 'Resume File': resume_file, 'Cosine Similarity': similarity})\n",
    "\n",
    "print(f\"Results saved to {output_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaba3ac-080a-4474-8714-796a0fce974f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a43c9-388e-4e4a-9074-37459039e64a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
